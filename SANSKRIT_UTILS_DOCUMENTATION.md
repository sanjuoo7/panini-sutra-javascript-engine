# Sanskrit Utilities Documentation

## Overview

The `sanskrit-utils` library is a comprehensive collection of utilities for Sanskrit linguistic analysis, developed for the Panini Sutra JavaScript Engine. It provides modular, well-tested functions for script detection, phoneme analysis, classification, morphological operations, and more.

## Table of Contents

1. [Core Modules](#core-modules)
2. [Constants & Data](#constants--data)
3. [Quick Start Guide](#quick-start-guide)
4. [API Reference](#api-reference)
5. [Usage Examples](#usage-examples)
6. [Migration Guide](#migration-guide)
7. [Testing & Validation](#testing--validation)

---

## Core Modules

### 1. **Script Detection** (`script-detection.js`)
**Purpose**: Identifies and validates Sanskrit text scripts (IAST, Devanagari, Mixed)

**Key Functions**:
- `detectScript(text)` - Returns 'IAST', 'Devanagari', 'Mixed', or 'Unknown'
- `isDevanagari(text)` - Boolean check for Devanagari script
- `isIAST(text)` - Boolean check for IAST script
- `analyzeScript(text)` - Detailed script analysis with statistics

**Use Cases**: Input validation, script-specific processing, mixed-script handling

### 2. **Phoneme Classification** (`classification.js`)
**Purpose**: Classifies Sanskrit phonemes according to Paninian grammar

**Key Functions**:
- `isVrddhi(vowel)` - Checks for ‡§µ‡•É‡§¶‡•ç‡§ß‡§ø vowels (ƒÅ, ai, au)
- `isGuna(vowel)` - Checks for ‡§ó‡•Å‡§£ vowels (a, e, o)  
- `isIkVowel(vowel)` - Checks for ‡§á‡§ï‡•ç vowels (i, ƒ´, u, ≈´, ·πõ, ·πù, ·∏∑, ·∏π)
- `isVowel(char)` - General vowel classification
- `isConsonant(char)` - General consonant classification
- `getVowelClassifications(vowel)` - Returns all applicable classifications

**Use Cases**: Grammatical analysis, sandhi rules, morphological operations

### 3. **Phoneme Tokenization** (`phoneme-tokenization.js`)
**Purpose**: Breaks Sanskrit text into individual phonemes for analysis

**Key Functions**:
- `tokenizePhonemes(text, options = {})` - Auto-detects script and tokenizes
- `tokenizeIastPhonemes(text)` - IAST-specific tokenization
- `tokenizeDevanagariPhonemes(text, options = {})` - Devanagari-specific tokenization with accuracy modes
- `analyzePhonemeStructure(text)` - Detailed phonemic analysis

**New Features**:
- **Accurate Mode**: Use `{ accurate: true }` for phonetically correct Devanagari tokenization
- **Inherent Vowel Handling**: Properly handles inherent '‡§Ö' vowels in Devanagari
- **Backward Compatibility**: Default mode preserves existing behavior

**Use Cases**: Phonological analysis, metre analysis, morpheme segmentation, grammatical rule application

### 4. **Vowel Analysis** (`vowel-analysis.js`)
**Purpose**: Specialized analysis and operations on Sanskrit vowels

**Key Functions**:
- `analyzeVowel(vowel)` - Comprehensive vowel analysis
- `getFirstVowel(text)` - Extracts first vowel for operations
- `getAllVowels(text)` - Returns all vowels with positions
- `applyGunaTransformation(vowel)` - ‡§ó‡•Å‡§£ vowel gradation
- `applyVrddhiTransformation(vowel)` - ‡§µ‡•É‡§¶‡•ç‡§ß‡§ø vowel gradation
- `getGunaVrddhiScope(text)` - Determines applicable gradations

**Use Cases**: Sandhi operations, verbal conjugation, nominal declension

### 5. **Validation** (`validation.js`)
**Purpose**: Input validation and sanitization for Sanskrit text

**Key Functions**:
- `validateSanskritWord(word)` - Validates Sanskrit word structure
- `validatePhonemeSequence(sequence)` - Validates phoneme combinations
- `validateVowel(vowel)` - Vowel-specific validation
- `sanitizeInput(text)` - Cleans and normalizes input
- `isValidCombination(phonemes)` - Checks phoneme combination rules

**Use Cases**: Input processing, error handling, data quality assurance

### 6. **Similarity Analysis** (`similarity-analysis.js`)
**Purpose**: Calculates phonetic and grammatical similarity between Sanskrit elements

**Key Functions**:
- `analyzeSimilarity(element1, element2)` - Comprehensive similarity analysis
- `calculatePhoneticSimilarity(sound1, sound2)` - Sound-based similarity
- `calculateArticulatorySimilarity(consonant1, consonant2)` - Articulatory feature comparison
- `findClosestSubstitute(target, candidates)` - Finds best phonetic match
- `getVowelLength(vowel)` - Vowel length classification
- `getConsonantType(consonant)` - Consonant articulatory classification

**Use Cases**: Morphological operations, phonetic substitutions, comparative analysis

### 7. **Transliteration** (`transliteration.js`)
**Purpose**: Converts between IAST and Devanagari scripts

### 8. **Conjunct Analysis** (`conjunct-analysis.js`)
**Purpose**: Comprehensive analysis of Sanskrit conjunct consonants (sa·πÉyoga)

**Key Functions**:
- `hasConjunct(consonantSequence)` - Detects presence of conjunct patterns
- `findConjuncts(text)` - Finds all conjunct patterns with positions
- `isConjunctPattern(pattern, script)` - Validates specific conjunct patterns
- `analyzeConjunctUsage(text)` - Provides detailed conjunct statistics
- `getConjunctPatterns(script)` - Returns conjunct pattern database
- `validateConjunctPattern(pattern, script)` - Validates conjunct format

**Pattern Database**: 150+ conjunct patterns for both Devanagari and IAST scripts

**Use Cases**: Phonological analysis, morphological operations, grammatical rule application (especially sutras 1.2.5)

### 9. **Verb Analysis** (`verb-analysis.js`)
**Purpose**: Analysis of Sanskrit verbal affixes and forms

**Key Functions**:
- `isLitAffix(affix)` - Identifies perfect tense (li·π≠) affixes
- `isSarvadhatuka(affix)` - Identifies primary verbal (sƒÅrvƒÅdhƒÅtuka) affixes
- `isPitAffix(affix)` - Identifies pit-designated affixes
- `analyzeAffix(affix)` - Comprehensive affix analysis
- `getAffixesByType(type, script)` - Returns affix sets by classification
- `validateAffix(affix)` - Validates affix format and recognition
- `findVerbalAffixes(text)` - Finds verbal affixes in text

**Affix Databases**: Complete sets of li·π≠, sƒÅrvƒÅdhƒÅtuka, and pit affixes for both scripts

**Use Cases**: Verbal morphology, tense identification, grammatical analysis (sutras 1.2.4, 1.2.5, 1.2.6)

### 10. **Root Analysis** (`root-analysis.js`)
**Purpose**: Analysis of Sanskrit verbal roots (dhƒÅtu) with variant recognition

**Key Functions**:
- `isVijRoot(root)`, `isUrnaRoot(root)`, `isIndhiRoot(root)`, `isBhuRoot(root)` - Specific root identification
- `isIndhiBhavatiRoot(root)` - Combined identification for sutras 1.2.6
- `getRootVariants(root)` - Returns all variants of a root
- `normalizeRoot(root)` - Normalizes variants to base form
- `analyzeRoot(root)` - Comprehensive root analysis with metadata
- `hasItAugment(root)` - Detects i·π≠-augment patterns
- `findSpecificRoots(text)` - Finds specific roots in text
- `validateRoot(root)` - Validates root format and recognition

**Root Database**: Specific roots (‡§µ‡§ø‡§ú‡•ç, ‡§ä‡§∞‡•ç‡§£, ‡§á‡§®‡•ç‡§ß‡§ø, ‡§≠‡•Ç) with variants, meanings, and sutra references

**Use Cases**: Root identification, morphological analysis, grammatical rule application (sutras 1.2.2, 1.2.3, 1.2.6)

### 11. **Kit Designation** (`kit-designation.js`)
**Purpose**: Analysis and determination of ‡§ï‡§ø‡§§‡•ç (kit) designation for Sanskrit affixes according to PƒÅ·πáinian rules

**Key Functions**:
- `analyzeKitDesignation(root, affix, context)` - Comprehensive ‡§ï‡§ø‡§§‡•ç analysis with sutra application
- `isSutra128Root(root)` - Checks if root is in Sutra 1.2.8 enumeration (‡§∞‡•Å‡§¶‡•ç, ‡§µ‡§ø‡§¶‡•ç, ‡§Æ‡•Å‡§∑‡•ç, etc.)
- `isKitBySutra128(root, affix)` - Determines ‡§ï‡§ø‡§§‡•ç by Sutra 1.2.8 (specific root-affix combinations)
- `isKitBySutra129(root, affix)` - Determines ‡§ï‡§ø‡§§‡•ç by Sutra 1.2.9 (‡§á‡§ï‡•ç-ending roots + ‡§∏‡§®‡•ç)
- `isKitBySutra1210(root, affix)` - Determines ‡§ï‡§ø‡§§‡•ç by Sutra 1.2.10 (‡§π‡§≤‡•ç-ending roots + ‡§∏‡§®‡•ç)
- `isKitBySutra1214(root, affix)` - Determines ‡§ï‡§ø‡§§‡•ç by Sutra 1.2.14 (‡§π‡§®‡•ç root with ‡§∏‡§ø‡§ö‡•ç)
- `isKitBySutra1215(root, affix, meaning)` - Determines ‡§ï‡§ø‡§§‡•ç by Sutra 1.2.15 (‡§Ø‡§Æ‡•ç root with ‡§∏‡§ø‡§ö‡•ç)
- `isSthaRoot(root)` - Identifies ‡§∏‡•ç‡§•‡§æ (sthƒÅ) root and variants for Sutra 1.2.17
- `isGhuClassRoot(root)` - Identifies ‡§ò‡•Å class roots (‡§π‡•Å, ‡§¶‡§æ, ‡§ß‡§æ, etc.) for Sutra 1.2.17
- `isKtvAffix(affix)` - Identifies ‡§ï‡•ç‡§§‡•ç‡§µ‡§æ affix including augmented forms (‡§á‡§ï‡•ç‡§§‡•ç‡§µ‡§æ, iktvƒÅ)
- `hasSetAugment(affix, context)` - Detects ‡§∏‡•á‡§ü‡•ç (i·π≠) augment in affixes for Sutra 1.2.18
- `isKtvaOrSanAffix(affix)` - Identifies ‡§ï‡•ç‡§§‡•ç‡§µ‡§æ and ‡§∏‡§®‡•ç affixes
- `isSanAffix(affix)` - Identifies ‡§∏‡§®‡•ç (desiderative) affixes specifically
- `isSicAffix(affix)` - Identifies ‡§∏‡§ø‡§ö‡•ç affix
- `isLingAffix(affix)` - Identifies ‡§≤‡§ø‡§ô‡•ç affix
- `isHanRoot(root)`, `isYamRoot(root)`, `isGamRoot(root)` - Specific root identification
- `endsWithIka(root)` - Checks if root ends with ‡§á‡§ï‡•ç vowels (i, u, ·πõ, ·∏∑)
- `endsWithHal(root)` - Checks if root ends with ‡§π‡§≤‡•ç consonants
- `beginsWithJhal(affix)` - Checks if affix begins with ‡§ù‡§≤‡•ç consonants

**Root Database**: Comprehensive collection of roots for sutras 1.2.8-1.2.15 with variants and morphological patterns

**Constants**: 
- `KIT_DESIGNATION_ROOTS` - Categorized roots by sutra
- `KIT_ROOT_VARIANTS` - Root variants and alternative forms
- `KIT_AFFIXES` - Affix patterns and classifications

**Supported Sutras**: 1.2.8, 1.2.9, 1.2.10, 1.2.14, 1.2.15, 1.2.16, 1.2.17, 1.2.18 with proper precedence handling

**Use Cases**: ‡§ï‡§ø‡§§‡•ç designation analysis, morphological rule application, accent determination, desiderative formations

### 12. **Kit Analysis** (`kit-analysis.js`) üÜï
**Purpose**: Advanced analysis functions for ‡§ï‡§ø‡§§‡•ç (kit) designation and ‡§Ö‡§§‡§ø‡§¶‡•á‡§∂ (exception) rules, specifically for sutras 1.2.19-1.2.21

**Key Functions**:
- `hasSetAugment(affix, context)` - Detects ‡§∏‡•á‡§ü‡•ç (i·π≠) augment in affixes across multiple scripts
- `isKtvAffix(affix)` - Identifies ‡§ï‡•ç‡§§‡•ç‡§µ‡§æ affixes including augmented forms (‡§á‡§ï‡•ç‡§§‡•ç‡§µ‡§æ, iktvƒÅ) 
- `isGhuClassRoot(root)` - Identifies ‡§ò‡•Å class roots (‡§π‡•Å, ‡§¶‡§æ, ‡§ß‡§æ, etc.) for morphological analysis
- `isSthaRoot(root)` - Identifies ‡§∏‡•ç‡§•‡§æ (sthƒÅ) root and variants including ‡§¶‡•Ä‡§∞‡•ç‡§ò‡§∏‡•ç‡§•‡§æ

**Advanced Pattern Matching**:
- Multi-script support (IAST and Devanagari)
- Morphological variant detection
- Context-dependent analysis for complex grammatical environments

**Supported Analysis**:
- ‡§∏‡•á‡§ü‡•ç augment detection in ‡§®‡§ø‡§∑‡•ç‡§†‡§æ affixes
- Exception handling for ‡§ï‡§ø‡§§‡•ç designation prevention (‡§Ö‡§§‡§ø‡§¶‡•á‡§∂ rules)
- Root classification for specific grammatical contexts
- Pattern matching for complex morphological forms

**Use Cases**: Exception rule application (sutras 1.2.19-1.2.21), advanced ‡§ï‡§ø‡§§‡•ç analysis, morphological classification, augment detection

### 13. **Accent Analysis** (`accent-analysis.js`) üÜï
**Purpose**: Comprehensive Vedic accent analysis and classification according to PƒÅ·πáinian principles (Sutras 1.2.29-1.2.31)

**Key Functions**:
- `analyzeVowelAccent(vowel, options)` - Complete vowel accent analysis with script detection
- `extractAccentMarks(vowel, script)` - Extracts accent marks from vowels
- `determineAccentType(accentMarks, script, strict)` - Classifies accent type (udƒÅtta, anudƒÅtta, svarita)
- `isUdattaMark(mark, script)` - Identifies udƒÅtta (high tone/acute) marks
- `isAnudattaMark(mark, script)` - Identifies anudƒÅtta (low tone/grave) marks  
- `isSvaritaMark(mark, script)` - Identifies svarita (combined tone/circumflex) marks
- `isUdatta(vowel, options)` - Boolean check for udƒÅtta vowels
- `isAnudatta(vowel, options)` - Boolean check for anudƒÅtta vowels
- `isSvarita(vowel, options)` - Boolean check for svarita vowels
- `applyUdatta(vowel)` - Adds udƒÅtta accent to vowel
- `applyAnudatta(vowel)` - Adds anudƒÅtta accent to vowel
- `applySvarita(vowel)` - Adds svarita accent to vowel
- `getAccentVariants(vowel)` - Returns all accent variants of a vowel

**Accent Constants**:
- `ACCENT_TYPES` - Standard accent classifications (udƒÅtta, anudƒÅtta, svarita)
- `ACCENT_MARKERS` - Script-specific accent mark mappings for IAST and Devanagari

**Advanced Features**:
- **Unicode Normalization**: Handles both precomposed (√¢) and decomposed (a + ÃÇ) accent characters
- **Multi-script Support**: Works with both IAST and Devanagari accent notation
- **Context Analysis**: Supports phonetic context analysis for accent determination
- **Strict/Lenient Modes**: Configurable strict mode for explicit marking requirements
- **Integration Ready**: Designed for sutras 1.2.29 (udƒÅtta), 1.2.30 (anudƒÅtta), 1.2.31 (svarita)

**Linguistic Foundation**: Based on traditional Vedic accent system where:
- **‡§â‡§¶‡§æ‡§§‡•ç‡§§ (UdƒÅtta)**: High tone, marked with acute accent (√°) in IAST
- **‡§Ö‡§®‡•Å‡§¶‡§æ‡§§‡•ç‡§§ (AnudƒÅtta)**: Low tone, marked with grave accent (√†) in IAST  
- **‡§∏‡•ç‡§µ‡§∞‡§ø‡§§ (Svarita)**: Combined/circumflex tone, marked with circumflex (√¢) in IAST

**Use Cases**: Vedic accent classification, tone analysis, accent-sensitive grammatical rules, prosodic analysis

**Created For**: Three-sutra accent classification trilogy (1.2.29-1.2.31) implementing complete Vedic accent terminology

### 14. **Accent Prosody Analysis** (`accent-prosody-analysis.js`) üÜï
**Purpose**: Higher-level prosodic interpretation built on accent analysis ‚Äì svarita internal segmentation (1.2.32), ekashruti monotone rule (1.2.33), ritual monotone with exceptions (1.2.34), va·π£a·π≠ raised option (1.2.35), and chandas optional monotone (1.2.36).

**Key Functions**:
- `decomposeSvarita(vowel, options)` - Returns temporal/pitch segments for svarita vowel (udƒÅtta-initial + anudƒÅtta-fall)
- `classifyEkashruti(text, context)` - Boolean classification for distant vocative monotone condition
- `applyEkashruti(text, context, options)` - Applies monotone override, optionally flattening accent marks
- `aggregateProsodyOptions(text, context, options)` - Aggregates layered prosodic possibilities (accented, monotone-forced, monotone, raised) evaluating sutras 1.2.32‚Äì1.2.36.

**Features**:
- Fixed half-unit udƒÅtta onset per 1.2.32
- Duration unit inference (hrasva/dirgha) with extensible mapping
- Distance threshold & semantic context support
- Unicode-safe accent stripping
- Context layering & precedence (Pattern F extension): ritual forcing > lexical raise > chandas optional > distance vocative optional
- Exception gating (japa, O·πÉ variants, sƒÅma) prevents ritual forcing per 1.2.34
- Option de-duplication via stable map keying (form+mode)

**Use Cases**: Prosody-aware chanting tools, pitch contour modeling, sacrificial recitation planners, metrical recitation simulators.

**Created For**: Sutras 1.2.32‚Äì1.2.36 (prosodic refinement, contextual override & optionalization)

**Example**:
```js
aggregateProsodyOptions('va·π£a·π≠', { ritual: true });
// {
//  options: [
//    { form: 'va·π£a·π≠', mode: 'accented', sources:['base'] },
//    { form: 'va·π£a·π≠', mode: 'monotone-forced', sources:['1.2.34-ritual-default'] },
//    { form: 'va·π£a·π≠ÃÅ', mode: 'raised', sources:['1.2.35'] }
//  ],
//  primaryDecision: 'options',
//  appliedSutras: ['1.2.34','1.2.35','1.2.33?'],
//  reasoning: [...]
// }
```

### 14b. **Accent Domain Rules** (`accent-domain-rules.js`) üÜï
**Purpose**: Domain & assimilation layer (1.2.37‚Äì1.2.39) extending aggregate prosody decisions.

**Key Functions**:
- `integrateDomainProsody(aggregateResult, context)` ‚Äì Applies:
  - 1.2.37 subrahma·πáyƒÅ: blocks monotone, svarita‚ÜíudƒÅtta (adds `udaatta-replaced` mode)
  - 1.2.38 lexical overrides (deva, brƒÅhma·πáa) ‚Üí `lexical-anudatta`
  - 1.2.39 local svarita‚ÜíanudƒÅtta run assimilation ‚Üí `local-monotone` option

**Modes Added**: `udaatta-replaced`, `lexical-anudatta`, `local-monotone`.
**Reason Tags**: `1.2.37-svarita-to-udaatta`, `1.2.37-block-monotone`, `1.2.38-lexical-anudatta`, `1.2.39-local-monotone-span`.

**Precedence Extension**:
Domain prohibitions > lexical overrides > local assimilation > earlier global/context options (ritual/chandas/distance, etc.).

**Example**:
```js
const agg = aggregateProsodyOptions('√¢√†√†', {});
// options include local-monotone variant from 1.2.39 if run detected
```


### 15. **Pada Analysis** (`pada-analysis.js`) üÜï
**Purpose**: Voice classification for Sanskrit verbal affixes (ƒÄtmanepada and Parasmaipada)

**Key Functions**:
- `isAtmanepadaAffix(affix, tense)` - Identifies ƒÄtmanepada (middle voice) endings
- `isParasmaipadaAffix(affix, tense)` - Identifies Parasmaipada (active voice) endings  
- `getAffixPada(affix, tense)` - Determines pada classification with tense details
- `getAffixesByPada(pada, tense, script)` - Returns affix sets by voice and tense
- `validatePadaAnalysis(affix, expectedPada)` - Validates pada classification

**Affix Databases**: Comprehensive voice-classified endings for all tense systems (la·π≠, li·π≠, lo·π≠, li·πÖ, lu·πÖ, l·πõ·π≠, l·πõ·πÖ)

**Use Cases**: Voice identification, morphological analysis, ƒÄtmanepada-specific rules (sutra 1.2.11)

**Created For**: Sutra 1.2.11 implementation - extends ‡§ï‡§ø‡§§‡•ç designation to voice-specific contexts
- `findPadaAffixes(text)` - Finds and classifies all pada affixes in text

**Affix Database**: 
- `ATMANEPADA_AFFIXES` - Complete ‡§Ü‡§§‡•ç‡§Æ‡§®‡•á‡§™‡§¶ affix inventory by tense (present, perfect, imperative, potential, aorist)
- `PARASMAIPADA_AFFIXES` - Complete ‡§™‡§∞‡§∏‡•ç‡§Æ‡•à‡§™‡§¶ affix inventory by tense

**Tense Support**: ‡§≤‡§ü‡•ç (present), ‡§≤‡§ø‡§ü‡•ç (perfect), ‡§≤‡•ã‡§ü‡•ç (imperative), ‡§≤‡§ø‡§ô‡•ç (potential), ‡§≤‡•Å‡§ô‡•ç (aorist), and more

**Features**:
- Multi-script support (Devanagari and IAST)
- Tense-specific classification
- Person and number analysis
- Comprehensive validation with suggestions
- Integration with morphological analysis

**Use Cases**: Voice determination, morphological analysis, grammatical rule application (sutras involving ‡§Ü‡§§‡•ç‡§Æ‡§®‡•á‡§™‡§¶/‡§™‡§∞‡§∏‡•ç‡§Æ‡•à‡§™‡§¶ distinctions like 1.2.11)

### 16. **Transliteration** (`transliteration.js`)
**Purpose**: Converts between IAST and Devanagari scripts

**Key Functions**:
- `iastToDevanagari(text)` - IAST ‚Üí Devanagari conversion
- `devanagariToIast(text)` - Devanagari ‚Üí IAST conversion
- `normalizeScript(text, targetScript)` - Script normalization
- `transliteratePhonemes(phonemes, targetScript)` - Phoneme-level transliteration

**Use Cases**: Script conversion, input normalization, output formatting

### 17. **Morphological Analysis** (`morphology.js`)
**Purpose**: Morphological operations and stem analysis

**Key Functions**:
- `analyzeMorphology(word)` - Morphological breakdown
- `extractStem(word)` - Stem extraction
- `identifyAffixes(word)` - Affix identification
- `classifyMorpheme(morpheme)` - Morpheme classification

**Use Cases**: Word analysis, grammatical parsing, morphological generation

---

## Constants & Data

### **SanskritVowels** (`constants.js`)
Contains comprehensive vowel classifications:
```javascript
// ‡§µ‡•É‡§¶‡•ç‡§ß‡§ø vowels (1.1.1)
vrddhi: {
  iast: ['ƒÅ', 'ai', 'au'],
  devanagari: ['‡§Ü', '‡§ê', '‡§î']
}

// ‡§ó‡•Å‡§£ vowels (1.1.2)  
guna: {
  iast: ['a', 'e', 'o'],
  devanagari: ['‡§Ö', '‡§è', '‡§ì']
}

// ‡§á‡§ï‡•ç vowels (1.1.3)
ik: {
  iast: ['i', 'ƒ´', 'u', '≈´', '·πõ', '·πù', '·∏∑', '·∏π'],
  devanagari: ['‡§á', '‡§à', '‡§â', '‡§ä', '‡§ã', '‡•†', '‡§å', '‡•°']
}
```

### **SanskritConsonants** (`constants.js`)
Organized by place of articulation:
```javascript
// Organized by articulatory positions
stops: {
  velars: { iast: ['k', 'kh', 'g', 'gh', '·πÖ'], devanagari: ['‡§ï', '‡§ñ', '‡§ó', '‡§ò', '‡§ô'] },
  palatals: { iast: ['c', 'ch', 'j', 'jh', '√±'], devanagari: ['‡§ö', '‡§õ', '‡§ú', '‡§ù', '‡§û'] },
  // ... etc
}

// Special consonant endings
specialEndings: {
  iast: ['·∏•', '·πÉ'], // visarga, anusvara
  devanagari: ['‡§É', '‡§Ç']
}
```

### **SanskritWordLists** (`constants.js`)
Important word lists for grammatical analysis:
```javascript
// ‡§∏‡§∞‡•ç‡§µ‡§æ‡§¶‡§ø words (1.1.27, 1.1.30, 1.1.31)
sarvaadi: {
  iast: ['sarva', 'vi≈õva', 'ubha', 'ubhaya', 'itara', 'anya', ...],
  devanagari: ['‡§∏‡§∞‡•ç‡§µ', '‡§µ‡§ø‡§∂‡•ç‡§µ', '‡§â‡§≠', '‡§â‡§≠‡§Ø', '‡§á‡§§‡§∞', '‡§Ö‡§®‡•ç‡§Ø', ...]
}

// Interrogatives (1.1.25)
interrogatives: {
  iast: ['kati', 'kiyati'],
  devanagari: ['‡§ï‡§§‡§ø', '‡§ï‡§ø‡§Ø‡§§‡§ø']
}
```

---

## Quick Start Guide

### Installation
```javascript
// Import specific utilities
import { detectScript, isVrddhi, tokenizePhonemes } from '../sanskrit-utils/index.js';

// Import specific modules
import { SanskritVowels } from '../sanskrit-utils/constants.js';
import { analyzeVowel } from '../sanskrit-utils/vowel-analysis.js';

// Import all utilities (not recommended for production)
import * as SanskritUtils from '../sanskrit-utils/index.js';
```

### Basic Usage
```javascript
// 1. Script Detection
const script = detectScript('‡§∞‡§æ‡§Æ‡§É'); // Returns 'Devanagari'
const script2 = detectScript('rƒÅma·∏•'); // Returns 'IAST'

// 2. Phoneme Analysis
const phonemes = tokenizePhonemes('‡§∞‡§æ‡§Æ‡§É');
// Returns: ['‡§∞', '‡§Ü', '‡§Æ', '‡§É']

// 3. Vowel Classification
const isVrddhiVowel = isVrddhi('‡§Ü'); // Returns true
const isGunaVowel = isGuna('‡§è'); // Returns true

// 4. Morphological Analysis
const vowelAnalysis = analyzeVowel('‡§Ü');
// Returns: { type: 'vrddhi', length: 'long', script: 'Devanagari', ... }
```

---

## Recent Refactoring (December 2024)

**Major Utility Extraction Completed**: Successfully extracted shared patterns from sutras 1.1.67-1.2.6 into comprehensive utility modules:

### Newly Added Modules (December 2024)

#### conjunct-analysis.js
- **Purpose**: Comprehensive analysis of Sanskrit conjunct consonants (sa·πÉyoga)
- **Functions**: `hasConjunct()`, `findConjuncts()`, `isConjunctPattern()`, `analyzeConjunctUsage()`
- **Data**: 150+ conjunct patterns for both Devanagari and IAST scripts
- **Used by**: Sutras 1.2.5 and other rules dealing with consonant clusters
- **Test Coverage**: 30 comprehensive test cases

#### verb-analysis.js  
- **Purpose**: Analysis of Sanskrit verbal affixes and forms
- **Functions**: `isLitAffix()`, `isSarvadhatuka()`, `isPitAffix()`, `analyzeAffix()`
- **Data**: Complete affix databases (li·π≠, sƒÅrvƒÅdhƒÅtuka, pit affixes)
- **Used by**: Sutras 1.2.4, 1.2.5 and other verbal morphology rules
- **Test Coverage**: 39 comprehensive test cases

#### root-analysis.js
- **Purpose**: Analysis of Sanskrit verbal roots with variant recognition  
- **Functions**: `isVijRoot()`, `isUrnaRoot()`, `isIndhiRoot()`, `isBhuRoot()`, `analyzeRoot()`
- **Data**: Specific root databases with variants and meanings for sutras 1.2.2, 1.2.3, 1.2.6
- **Used by**: Sutras 1.2.2 (‡§µ‡§ø‡§ú‡•ç), 1.2.3 (‡§ä‡§∞‡•ç‡§£), 1.2.6 (‡§á‡§®‡•ç‡§ß‡§ø/‡§≠‡•Ç)
- **Test Coverage**: 47 comprehensive test cases

### Refactored Sutras

The following sutras have been successfully refactored to use shared utilities:

- **Sutra 1.2.2**: Now uses `isVijRoot()` from root-analysis utility
- **Sutra 1.2.3**: Now uses `isUrnaRoot()` from root-analysis utility  
- **Sutra 1.2.4**: Now uses `isSarvadhatuka()` and `isPitAffix()` from verb-analysis utility
- **Sutra 1.2.5**: Now uses `hasConjunct()` and `isLitAffix()` from conjunct-analysis and verb-analysis utilities
- **Sutra 1.2.6**: Now uses `isIndhiRoot()`, `isBhuRoot()` from root-analysis utility

All refactored sutras maintain backward compatibility through re-exports and function aliases.

## API Reference

### Core Utility Functions

#### `detectScript(text: string): string`
**Purpose**: Detects the script of input text
**Parameters**: 
- `text` - Text to analyze
**Returns**: 'IAST' | 'Devanagari' | 'Mixed' | 'Unknown'
**Example**:
```javascript
detectScript('‡§∞‡§æ‡§Æ'); // 'Devanagari'
detectScript('rƒÅma'); // 'IAST'
```

#### `tokenizePhonemes(text: string, options?: object): object`
**Purpose**: Breaks text into individual phonemes with script detection
**Parameters**:
- `text` - Text to tokenize
- `options` - Optional configuration object
  - `accurate` - Boolean, enables phonetically accurate Devanagari tokenization (default: false)
**Returns**: Object with phonemes array, script, count, and metadata
**Example**:
```javascript
// Legacy mode (default)
tokenizePhonemes('‡§∞‡§æ‡§Æ'); // { phonemes: ['‡§∞', '‡§æ', '‡§Æ'], script: 'Devanagari', ... }
tokenizePhonemes('rƒÅma'); // { phonemes: ['r', 'ƒÅ', 'm', 'a'], script: 'IAST', ... }

// Accurate mode (phonetically correct for Devanagari)
tokenizePhonemes('‡§∞‡§æ‡§Æ', { accurate: true }); // { phonemes: ['‡§∞', '‡§æ', '‡§Æ', '‡§Ö'], script: 'Devanagari', ... }
```

#### `tokenizeDevanagariPhonemes(text: string, options?: object): string[]`
**Purpose**: Devanagari-specific phoneme tokenization
**Parameters**:
- `text` - Devanagari text to tokenize
- `options` - Optional configuration object
  - `accurate` - Boolean, enables phonetically accurate tokenization (default: false)
**Returns**: Array of phoneme strings
**Example**:
```javascript
// Legacy mode (character-based)
tokenizeDevanagariPhonemes('‡§Æ‡§®'); // ['‡§Æ', '‡§®']

// Accurate mode (with inherent vowels)
tokenizeDevanagariPhonemes('‡§Æ‡§®', { accurate: true }); // ['‡§Æ', '‡§Ö', '‡§®', '‡§Ö']
tokenizeDevanagariPhonemes('‡§∞‡§æ‡§Æ‡•ç', { accurate: true }); // ['‡§∞', '‡§æ', '‡§Æ', '‡•ç']
```

#### `isVrddhi(vowel: string): boolean`
**Purpose**: Checks if vowel is ‡§µ‡•É‡§¶‡•ç‡§ß‡§ø (ƒÅ, ai, au)
**Parameters**:
- `vowel` - Vowel character to check
**Returns**: Boolean
**Example**:
```javascript
isVrddhi('‡§Ü'); // true
isVrddhi('‡§á'); // false
```

#### `analyzeVowel(vowel: string): object`
**Purpose**: Comprehensive vowel analysis
**Parameters**:
- `vowel` - Vowel to analyze
**Returns**: Analysis object with type, length, script, etc.
**Example**:
```javascript
analyzeVowel('‡§Ü');
// {
//   type: 'vrddhi',
//   length: 'long',
//   script: 'Devanagari',
//   iastEquivalent: 'ƒÅ',
//   classifications: ['vrddhi', 'long']
// }
```

### Constants Access

#### `SanskritVowels`
**Structure**:
```javascript
{
  vrddhi: { iast: [...], devanagari: [...] },
  guna: { iast: [...], devanagari: [...] },
  ik: { iast: [...], devanagari: [...] },
  all: { iast: [...], devanagari: [...], diacritics: [...] }
}
```

#### `SanskritConsonants`
**Structure**:
```javascript
{
  stops: {
    velars: { iast: [...], devanagari: [...] },
    palatals: { iast: [...], devanagari: [...] },
    // ... other positions
  },
  semivowels: { iast: [...], devanagari: [...] },
  sibilants: { iast: [...], devanagari: [...] },
  specialEndings: { iast: [...], devanagari: [...] }
}
```

---

## Usage Examples

### Example 1: Sandhi Analysis
```javascript
import { detectScript, tokenizePhonemes, analyzeVowel, isVrddhi } from '../sanskrit-utils/index.js';

function prepareSandhiAnalysis(word1, word2) {
  // Detect scripts
  const script1 = detectScript(word1);
  const script2 = detectScript(word2);
  
  // Tokenize for analysis
  const phonemes1 = tokenizePhonemes(word1);
  const phonemes2 = tokenizePhonemes(word2);
  
  // Analyze final and initial sounds
  const finalSound = phonemes1[phonemes1.length - 1];
  const initialSound = phonemes2[0];
  
  // Check for vowel combinations
  const finalVowelAnalysis = analyzeVowel(finalSound);
  const initialVowelAnalysis = analyzeVowel(initialSound);
  
  return {
    scripts: { first: script1, second: script2 },
    phonemes: { first: phonemes1, second: phonemes2 },
    junction: { final: finalVowelAnalysis, initial: initialVowelAnalysis },
    applicableRules: determineSandhiRules(finalVowelAnalysis, initialVowelAnalysis)
  };
}
```

### Example 2: Morphological Classification
```javascript
import { SanskritWordLists, isVrddhi, isGuna } from '../sanskrit-utils/index.js';

function classifyWord(word) {
  // Check against known word lists
  const isSarvaadi = SanskritWordLists.sarvaadi.iast.includes(word) || 
                     SanskritWordLists.sarvaadi.devanagari.includes(word);
  
  const isInterrogative = SanskritWordLists.interrogatives.iast.includes(word) || 
                          SanskritWordLists.interrogatives.devanagari.includes(word);
  
  // Analyze vowel characteristics
  const phonemes = tokenizePhonemes(word);
  const vowels = phonemes.filter(p => isVowel(p));
  const hasVrddhi = vowels.some(v => isVrddhi(v));
  const hasGuna = vowels.some(v => isGuna(v));
  
  return {
    grammaticalClass: {
      isSarvaadi,
      isInterrogative,
      // ... other classifications
    },
    phoneticFeatures: {
      hasVrddhi,
      hasGuna,
      vowelCount: vowels.length,
      // ... other features
    }
  };
}
```

### Example 3: Input Validation Pipeline
```javascript
import { validateSanskritWord, sanitizeInput, detectScript } from '../sanskrit-utils/index.js';

function processSanskritInput(rawInput) {
  // Sanitize input
  const cleanInput = sanitizeInput(rawInput);
  
  // Validate as Sanskrit
  const validation = validateSanskritWord(cleanInput);
  if (!validation.isValid) {
    throw new Error(`Invalid Sanskrit input: ${validation.errors.join(', ')}`);
  }
  
  // Detect and normalize script
  const script = detectScript(cleanInput);
  
  return {
    original: rawInput,
    cleaned: cleanInput,
    script: script,
    isValid: validation.isValid,
    recommendations: validation.suggestions || []
  };
}
```

### Example 4: Kit Designation Analysis
```javascript
import { analyzeKitDesignation, isSutra128Root, isKtvaOrSanAffix } from '../sanskrit-utils/index.js';

function analyzeVerbMorphology(root, affix, context = {}) {
  // Comprehensive kit designation analysis
  const kitAnalysis = analyzeKitDesignation(root, affix, {
    ...context,
    debug: true  // Enable detailed analysis
  });
  
  // Check specific sutra applications
  const isSutra128Applicable = isSutra128Root(root) && isKtvaOrSanAffix(affix);
  
  // Determine morphological effects
  const morphologicalEffects = {
    accentPreservation: kitAnalysis.isKit,
    preventGuna: kitAnalysis.isKit && hasGunaContext(root, affix),
    sandhiRules: determineSandhiRules(root, affix, kitAnalysis.isKit)
  };
  
  return {
    kitDesignation: kitAnalysis,
    sutraApplication: {
      '1.2.8': isSutra128Applicable,
      applicable: kitAnalysis.applicableSutras || []
    },
    morphologicalImpact: morphologicalEffects,
    linguisticAnalysis: {
      rootType: classifyRoot(root),
      affixType: classifyAffix(affix),
      combination: `${root} + ${affix}`,
      explanation: kitAnalysis.explanation
    }
  };
}

// Helper function for gu·πáa context analysis
function hasGunaContext(root, affix) {
  const rootFinalVowel = getLastVowel(root);
  return isIkVowel(rootFinalVowel) && requiresGuna(affix);
}

// Usage example
const morphAnalysis = analyzeVerbMorphology('‡§∞‡•Å‡§¶‡•ç', '‡§ï‡•ç‡§§‡•ç‡§µ‡§æ', {
  meaning: 'having wept',
  tense: 'absolutive'
});

console.log(morphAnalysis.kitDesignation.isKit);        // true (by Sutra 1.2.8)
console.log(morphAnalysis.morphologicalImpact.accentPreservation); // true
```

---

## Migration Guide

### From Legacy `shared-utils.js`

**Old Way**:
```javascript
import { detectScript, tokenizePhonemes } from '../shared/shared-utils.js';
```

**New Way**:
```javascript
import { detectScript, tokenizePhonemes } from '../sanskrit-utils/index.js';
```

### Breaking Changes
1. **Module Structure**: Functions are now organized in separate modules
2. **Import Paths**: Changed from `../shared/` to `../sanskrit-utils/`
3. **Constants**: Now organized in structured objects (e.g., `SanskritVowels.vrddhi.iast`)

### Compatibility Layer
For backward compatibility, use the legacy compatibility layer:
```javascript
import { createLegacyUtils } from '../sanskrit-utils/index.js';

const legacyUtils = await createLegacyUtils();
// Use legacyUtils.detectScript(), etc.
```

---

## Testing & Validation

### Running Tests
```bash
# Run all sanskrit-utils tests
npm test sutras/sanskrit-utils/

# Run specific module tests
npm test sutras/sanskrit-utils/phoneme-tokenization.test.js

# Run integration tests with sutras
npm test sutras/1.1.*/index.test.js
```

### Test Coverage
The sanskrit-utils library maintains high test coverage:
- **Script Detection**: 95%+ coverage across all script types
- **Phoneme Tokenization**: 98%+ coverage with edge cases
- **Classification**: 100% coverage for all vowel/consonant types
- **Validation**: 90%+ coverage including error conditions

### Validation Utilities
```javascript
import { validateSanskritWord } from '../sanskrit-utils/validation.js';

// Validate input before processing
const validation = validateSanskritWord('‡§∞‡§æ‡§Æ‡§É');
console.log(validation);
// {
//   isValid: true,
//   script: 'Devanagari',
//   phonemeCount: 4,
//   warnings: [],
//   suggestions: []
// }
```

---

## Performance Considerations

### Optimization Tips
1. **Import only what you need**: Use specific imports rather than `import *`
2. **Cache analysis results**: Vowel and phoneme analysis results can be cached
3. **Batch operations**: Use batch functions for processing multiple words
4. **Script detection**: Cache script detection results for repeated text

### Memory Usage
- Constants are loaded once and shared across modules
- Phoneme tokenization uses minimal memory allocation
- Analysis functions avoid creating large intermediate objects

---

## Contributing

### Code Style
- Follow ESDoc documentation standards
- Include comprehensive tests for new functions
- Maintain backward compatibility when possible
- Use meaningful function and variable names

### Adding New Utilities
1. Create module in appropriate category
2. Export functions from `index.js`
3. Add comprehensive tests
4. Update this documentation
5. Add usage examples

---

## Changelog

### Version 2.0.0 (August 2025)
- **BREAKING**: Restructured from single file to modular architecture
- **ADDED**: Comprehensive vowel analysis utilities
- **ADDED**: Enhanced script detection with mixed-script support
- **ADDED**: Similarity analysis module
- **ADDED**: Validation and sanitization utilities
- **IMPROVED**: Phoneme tokenization accuracy
- **IMPROVED**: Constants organization and coverage

### Version 1.x (Legacy)
- Single-file shared-utils.js implementation
- Basic script detection and phoneme tokenization
- Limited vowel classification

---

## License & Credits

Part of the Panini Sutra JavaScript Engine project.
Developed for accurate implementation of Paninian grammar rules in JavaScript.

**Authors**: Sanskrit Computational Linguistics Team
**Created**: August 8, 2025
**Last Updated**: August 10, 2025
